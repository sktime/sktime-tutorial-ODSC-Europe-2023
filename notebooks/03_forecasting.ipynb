{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting with sktime\n",
    "Estimated time: 40 min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "What is a time series and what can we forecast?\n",
    "\n",
    "![](../images/ts_quiz.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factors that influence ”forecastability”:\n",
    "1. How much data is available.\n",
    "2. How similar the future is to the past.\n",
    "3. How well we understand the factors that contribute to it.\n",
    "4. Whether the forecasts can affect the thing we are trying to forecast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quickstart\n",
    "- Univariate forecasting\n",
    "    - With statistical models\n",
    "    - With machine learning models\n",
    "    - Model evaluation and selection\n",
    "- Univariate forecasting with exogenous data\n",
    "- Multivariate forecasting\n",
    "- Probabilistic forecasting\n",
    "- Hierarchical forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a typical usecase where you may have been given monthly historic sales data. It might look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "y = load_shampoo_sales()\n",
    "\n",
    "fig, ax = plot_series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y=y, test_size=6)\n",
    "fig, ax = plot_series(y_train, y_test, labels=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "# 1) Define the model\n",
    "forecaster = AutoARIMA(suppress_warnings=True)\n",
    "\n",
    "# 2) Fit on train data\n",
    "forecaster.fit(y_train)\n",
    "\n",
    "# 3) Use fitted model to predict for a certain forecast horizon (fh)\n",
    "fh = [1, 2, 3, 4, 5, 6] # Relative to y_train\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have access to the true value of our predictions, as is the case here, we can score the model using the different performance metrics available in `sktime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "\n",
    "smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "\n",
    "print(f\"AutoARIMA - sMAPE error: {smape(y_test, y_pred):.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on MAPE: we will be using the MAPE (here in its `symmetric` variant) as it is well-known and easy to interpret, but this is not necesarily always the best metric. We encourage users to explore the different metrics available.\n",
    "\n",
    "Note on single train-test spli: here we presented prediction results on one single data split. This is not the bst way to evaluate model performance but it is easy to showcase. We will explore a best practice approach once we get familiar with the forecasting interface."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go over the two most popular approaches for forecasting univariate time series in `sktime`:\n",
    "- Classical statistical (econometric) models\n",
    "- Machine learning (reduction) models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical (classical) forecasting methods\n",
    "\n",
    "We can emplore other different stats-based forecasting method availble in `sktime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.tbats import TBATS\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecasters = [AutoETS(auto=True), TBATS()]\n",
    "\n",
    "for forecaster in forecasters:\n",
    "    y_pred = forecaster.fit_predict(y=y_train, fh=fh)\n",
    "    title = (\n",
    "        f\"{str(forecaster).split('(')[0]} - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "    )\n",
    "    fig, ax = plot_series(\n",
    "        y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"], title=title\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out all other sktime forecasting algorithms [in the documentation](https://www.sktime.net/en/latest/api_reference/forecasting.html) or by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"forecaster\", as_dataframe=True, suppress_import_stdout=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with ML algorithms (reduction)\n",
    "\n",
    "Another very popular approach for time series forecasting is using machine learning algorithms.\n",
    "\n",
    "Here we will show how to use an sklearn regressor (other popular models such as lightgbm or xgboost can be easily swapped in) to forecast th same sales time series we saw before.\n",
    "\n",
    "However, although we will be using tabular regressors, forecasting is not the same as supervised regression due to temporal sequencing!\n",
    "\n",
    "We need to transform our data into a tabular format first, with a table of features and a target columns like the one in the image below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/tabularization.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be tricky to do manually. Thankfully, `sktime` provides tools to make the reduction proceess fool-proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "\n",
    "# Can be swapped with XBGoost, LightGBM, CatBoost, etc.\n",
    "regressor = HistGradientBoostingRegressor()\n",
    "\n",
    "# Create a forecaster from the tabular regressor by wrapping it in `make_reduction`\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=16)\n",
    "\n",
    "y_pred = forecaster.fit_predict(y=y_train, fh=fh)\n",
    "title = f\"Gradient-boosted tree regressor - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering why the comparatively bad performance... \n",
    "\n",
    "Gradient boosting trees cannot extrapolate, so hey will not forecast values they have not seen.\n",
    "\n",
    "A simple way to address this is to apply a first-differencing transformation to the data before tabularization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data transformations are easy to use in `sktime` by employing transformers.\n",
    "\n",
    "Let's see how to use the `Differencer` transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "transformer = Differencer(lags=1)\n",
    "y_transform = transformer.fit_transform(y)\n",
    "fig, ax = plot_series(\n",
    "    y, y_transform, labels=[\"y\", \"y_diff\"], title=\"Difference transformation\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers can be combined (composed) with forecasters to modify their befaviour.\n",
    "\n",
    "Let's see how the tree-based forecaster behaves when we combine it with the `Differencer` transformer via the `*` dunder operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=16)\n",
    "forecaster_with_differencer = Differencer(lags=1) * forecaster\n",
    "\n",
    "y_pred = forecaster_with_differencer.fit_predict(y=y_train, fh=fh)\n",
    "title = f\"Gradient-boosted tree regressor with difference transform - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore transformers and composition in subsequent notebooks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model performance as we have been doing previously using a single split is not best practice as it can be unreliable. \n",
    "\n",
    "We can do a more robust evaluation by using `sktime`'s cross validation splitters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.utils.plotting import plot_windows\n",
    "\n",
    "cv = ExpandingWindowSplitter(initial_window=24, fh=fh, step_length=2)\n",
    "n_folds = cv.get_n_splits(y)\n",
    "plot_windows(cv, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtesting for single model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can leverage this more rebust cross-validation strategies for sinlge model evaluation by using `sktime`'s evaluat function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
    "\n",
    "forecaster = forecaster_with_differencer.clone()\n",
    "scorers = [smape, MeanSquaredError(square_root=True)]\n",
    "backtest = evaluate(\n",
    "    forecaster=forecaster, y=y, cv=cv, scoring=scorers, backend=\"dask\", return_data=True\n",
    ")\n",
    "backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest.loc[0, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_series(\n",
    "    y,\n",
    "    *tuple(backtest[\"y_pred\"][i] for i in range(n_folds)),\n",
    "    labels=[\"y\"] + [f\"fold_{i}\" for i in range(n_folds)],\n",
    "    title=f\"Backtest predictions, average sMAPE: {backtest['test_MeanAbsolutePercentageError'].mean():.1%}\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Benchmarking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to better assess the performance of a single model, but `sktime` also allows to assess a group of models in the same way by using the `ForecastingBenchmark` class. \n",
    "\n",
    "This can be helpfull in a model selection setting where you would like to find out which of a set of models performs best on historical data.\n",
    "\n",
    "Note: `ForecastingBenchmark` requires [`kotsu`](https://github.com/datavaluepeople/kotsu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating an instance of the `ForecastingBenchmark` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.benchmarking.forecasting import ForecastingBenchmark\n",
    "\n",
    "benchmark = ForecastingBenchmark()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add different models with the `add_estimator` method.\n",
    "\n",
    "Here we have addded the `NaiveForecaster` as a simple benchmark. This is often a good idea to be able to assess what the baseline prediction accuracy is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "benchmark.add_estimator(\n",
    "    estimator=NaiveForecaster(strategy=\"mean\", window_length=3),\n",
    "    estimator_id=\"Naive-mean-3-v1\",\n",
    ")\n",
    "benchmark.add_estimator(estimator=AutoARIMA(), estimator_id=\"AutoARIMA-v1\")\n",
    "benchmark.add_estimator(estimator=AutoETS(auto=True), estimator_id=\"AutoETS-v1\")\n",
    "benchmark.add_estimator(\n",
    "    estimator=forecaster_with_differencer.clone(), estimator_id=\"LightGBM-v1\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the cross-validation strategy and a list of scorers to set up the task for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ExpandingWindowSplitter(initial_window=24, fh=fh, step_length=2)\n",
    "scorers = [smape]\n",
    "\n",
    "benchmark.add_task(\n",
    "    load_shampoo_sales,\n",
    "    cv,\n",
    "    scorers,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we call the `run` method to start the benchmarking process and we can see the results for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = benchmark.run(output_file=\"results.csv\")\n",
    "results_df.set_index(\"model_id\").iloc[:, -2:].style.format(\"{:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmarking functionality is currently in active development over the summer programme. We are open to feedback and appreciate contributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we have only tacked a time single series, but it is often the case that we have access to other time series that we expect can help improve performance as it helps predict the time series we are interested in.\n",
    "\n",
    "A tipical example is when we are forecasting sales and have access to promotions, which we know drive sales. How can we make use of this additional data for forecasting?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate with exogenous"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the same sales data we have bee working on before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "\n",
    "y = load_shampoo_sales()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the sales data, noise and some simple transformations to create *fake* promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "# Use a differencer, clipping and some noise to generate fake promotional data\n",
    "transformer = Differencer(lags=1)\n",
    "y_transform = transformer.fit_transform(y)\n",
    "noise = np.random.RandomState(seed=93).normal(0, 100, np.shape(y))\n",
    "X_promo = (y_transform + noise).clip(lower=0)\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y, X_promo, labels=[\"y\", \"fake_promotions\"], title=\"Sales and Promotions\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split both the target time series (y: sales) and the exogenous time series (X: promotions) with the `temporal_train_test_split` we have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "fh = [1, 2, 3, 4]\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(\n",
    "    y=y, X=X_promo, test_size=len(fh)\n",
    ")\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y_train,\n",
    "    X_train,\n",
    "    y_test,\n",
    "    X_test,\n",
    "    labels=[\"y_train\", \"X_train\", \"y_train\", \"X_test\"],\n",
    "    title=\"Test and train: sales and promotions\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can forecast y (sales) also using the known values of future X (promotions) by passing the future X data in the predict step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "forecaster = AutoARIMA(suppress_warnings=True)\n",
    "\n",
    "# Use train data in fit\n",
    "forecaster.fit(y=y_train, X=X_train, fh=fh)\n",
    "\n",
    "# Note how the \"future\" data of X is passed in the predict step\n",
    "y_pred = forecaster.predict(X=X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the prediction looks like when adding promotional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "\n",
    "smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "\n",
    "title = f\"AutoARIMA with promotional data - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: as we created the promotions from the sales data, the performance upflift is over-optimistic (data leakage)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if don't have future promotional data?\n",
    "\n",
    "If we believe that we can forecast `X` (promotions) independently of `y` (sales) we can use these predictions of `X` to inform the predictions of `y`.\n",
    "\n",
    "Here, we decide to use a different model for `X` than for `y`. This may be the case when we expect a different model to perform better on `X` because the data is of a different nature. We illustrated this here by using the `Croston()` model for `X` as this is a model that is typically used on intermittent data (such as this fake promotion data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import ForecastX\n",
    "from sktime.forecasting.croston import Croston\n",
    "\n",
    "forecaster_X = ForecastX(\n",
    "    forecaster_y=AutoARIMA(suppress_warnings=True),\n",
    "    forecaster_X=Croston(),\n",
    ")\n",
    "forecaster_X.fit(y=y, X=X_promo, fh=fh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting on both `X` and `y` we can creat predictions of `y` directly. Under the hood `sktime` is forecasting `X` with the `Croston()` model and using it in the prediction step of `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in the `predict` step we don't need to pass X\n",
    "y_pred = forecaster_X.predict(fh=fh)\n",
    "\n",
    "title = f\"ForecastX: Using AutoARIMA for y (sales) and Croston for X (promotions)\"\n",
    "fig, ax = plot_series(\n",
    "    y, y_pred, labels=[\"y\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also happen that a single univariate time series in not your focus, but rather you are interested in forecasting a group of time series that represent different aspects of a single entity. \n",
    "\n",
    "As an example, you may be interested in forecasting several time series that are macroeconomic indicators that all measure \"the economy\". In this case, you would be interested in multivariate time series forecasting. Let's see how this can be done with `sktime`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the historical data of a couple of macro indicators, which are reported yearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "\n",
    "_, y = load_longley()\n",
    "\n",
    "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"])\n",
    "\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sktime` some forecasters such as `VAR()` are purely mutlivariate. Let's use it to make some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.var import VAR\n",
    "\n",
    "forecaster = VAR()\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "\n",
    "y_pred = forecaster.predict()\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspects the tags of the `VAR()` forecasteer through to `get_tags` to check its multivariate nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also use univariate forecasters to forecast multiple time series! Let's see how this is done using `ARIMA` which is a purely univariate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "\n",
    "_, y = load_longley()\n",
    "\n",
    "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"])\n",
    "\n",
    "forecaster = ARIMA()\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "\n",
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see `sktime` fits one single `ARIMA()` model per time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the nature of the `ARIMA()` model using the `get_tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now covered how to prodce point forcasts for univariate and multivariate data, but in many forecasting settings, point predictions are not enough. Your forcasts, even with the best models, will always carry some degree of uncertainty. \n",
    "\n",
    "Therefore, you may also want to be able to express this uncertainty in your forcasts by, for example, providing prdictions intervals. This can be done easily with `sktime`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "\n",
    "y = load_shampoo_sales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "# 1) Define the model\n",
    "forecaster = AutoETS(auto=True)\n",
    "\n",
    "# 2) Fit on train data\n",
    "forecaster.fit(y_train)\n",
    "\n",
    "# 3) Use fitted model to predict for a certain forecast horizon (fh)\n",
    "fh = [1, 2, 3, 4]\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "# 4) Call a probabilistic method after or in place of step 3\n",
    "y_pred_int = forecaster.predict_interval(coverage=0.95)\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"], pred_interval=y_pred_int\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods are possibly available for probabilistic forecasts:\n",
    "\n",
    "- `predict_interval` produces interval forecasts. Additionally to any `predict` arguments, an argument `coverage` (nominal interval coverage) must be provided.\n",
    "- `predict_quantiles` produces quantile forecasts. Additionally to any `predict` arguments, an argument `alpha` (quantile values) must be provided.\n",
    "- `predict_var` produces variance forecasts. This has same arguments as `predict`.\n",
    "- `predict_proba` produces full distributional forecasts. This has same arguments as `predict`.\n",
    "\n",
    "| Name | param | prediction/estimate of | `sktime` |\n",
    "| ---- | ----- | ---------------------- | -------- |\n",
    "| point forecast | | conditional expectation $\\mathbb{E}[y'\\|y]$ | `predict` |\n",
    "| variance forecast | | conditional variance $Var[y'\\|y]$ | `predict_var` |\n",
    "| quantile forecast | $\\alpha\\in (0,1)$ | $\\alpha$-quantile of $y'\\|y$ | `predict_quantiles` |\n",
    "| interval forecast | $c\\in (0,1)$| $[a,b]$ s.t. $P(a\\le y' \\le b\\| y) = c$ | `predict_interval` |\n",
    "| distribution forecast | | the law/distribution of $y'\\|y$ | `predict_proba` |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which estimators can perform probabiilistic forecasting by checking `all_stimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\n",
    "    \"forecaster\",\n",
    "    filter_tags={\"capability:pred_int\": True},\n",
    "    as_dataframe=True,\n",
    "    suppress_import_stdout=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  estimators that have the `pred_int` tag always have all the probabilistic methods available. So estimators either have all of them or none."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the difference probabilistic methods and their different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_interval(coverage=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_quantiles(alpha=[0.275, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_var()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict full predictive distributions, `predict_proba` can be used. This returns a `BaseDistribution` child instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_proba()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/hierarchy.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some sktime utilities to create a hierarchical dataframe of historical monthly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odsc_utils import load_product_hierarchy\n",
    "\n",
    "y = load_product_hierarchy()\n",
    "\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick a specific date to clearly see the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiindex slicing can become important when using hierarchical data!\n",
    "y.loc[(slice(None), slice(None), \"2000-01\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the different time series in the hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_index = y.droplevel(-1).index.unique()\n",
    "fig, ax = plot_series(*(y.loc[idx] for idx in product_index), labels=product_index, title=\"Product sales\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting this data simultaneously is easy as `sktime` automatically vectorizes/\"up-casts\" the models to hierarchical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecaster = AutoETS(auto=True)\n",
    "\n",
    "y_pred = forecaster.fit_predict(y, fh=[1])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with hierarchies we often want to provide forecasts of the aggregated levels too.\n",
    "\n",
    "Right now for this we would manually sum up the predictions for the lower levels that we are interested in.\n",
    "\n",
    "A better way to do this is by using the `Aggregator` transformer in `sktime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.hierarchical.aggregate import Aggregator\n",
    "\n",
    "y_hier = Aggregator().fit_transform(y)\n",
    "\n",
    "y_hier.loc[(slice(None), slice(None), \"2000-01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = AutoETS(auto=True, random_state=0)\n",
    "\n",
    "y_hier_pred = forecaster.fit_predict(y_hier, fh=1)\n",
    "y_hier_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the predictions at the top level with the sum of the bottom level forecast we can check that they are not the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "584.481241 - (119.460419 + 169.749332 + 146.466778 + 139.583316)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because independent instances of each forecaster are fitted per level and there is currently no constrain to ensure the predictions add up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `ReconcilerForecaster` enfore hierarchical reconciliation to solve this problem.\n",
    "\n",
    "The `ReconcilerForecaster` takes in a forecaster and add a reconciliation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.reconcile import ReconcilerForecaster\n",
    "\n",
    "reconciler_forecaster = ReconcilerForecaster(\n",
    "    forecaster=forecaster.clone(), method=\"bu\"\n",
    ")\n",
    "\n",
    "y_hier_pred = reconciler_forecaster.fit_predict(y_hier, fh=1)\n",
    "y_hier_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the top level and sum of the bottom level are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "575.259845 - (119.460419 + 169.749332 + 146.466778 + 139.583316)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retirieve the available reconciliation methods easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valid reconciliation methods:\")\n",
    "for method in ReconcilerForecaster.METHOD_LIST:\n",
    "    print(f\"- {method}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define different forecasters at different hierarchy levels (or hierarchy nodes) by using the `HierarchyEnsembleForecaster`. \n",
    "\n",
    "Forecasters built this way also aggregate the hierachical data for you under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odsc_utils import load_product_hierarchy\n",
    "\n",
    "y = load_product_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import HierarchyEnsembleForecaster\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecasters = [\n",
    "    ('Auto ARIMA', AutoARIMA(), 0),\n",
    "    ('Auto ETS', AutoETS(auto=True), 1)\n",
    "]\n",
    "\n",
    "forecaster = HierarchyEnsembleForecaster(\n",
    "                forecasters=forecasters,\n",
    "                by='level', default = AutoETS(auto=True)\n",
    ")\n",
    "\n",
    "y_pred = forecaster.fit_predict(y, fh=[1])\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we have been always forecasting the hierachical data locally, but we can also leverage global forecasting:\n",
    "- Local: fit a model to each time series locally\n",
    "- Global: fit a single model to all the series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of global forecasting:\n",
    "- The model has access to more data to learn from, great when individual time series are short.\n",
    "- Faster than local approach\n",
    "- Empirically shown to outperform local models (e.g. M5 forecasting competition)\n",
    "\n",
    "Note: global models assume the data generating procress for the group of time series is the same or at least similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odsc_utils import load_product_hierarchy\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "y = load_product_hierarchy()\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y_hier, test_size=4)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by using local forecasting with the gradient boosting regressor we used previously to forecast the hierarchical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=12, pooling=\"local\")\n",
    "\n",
    "y_pred = forecaster.fit_predict(y_train, fh=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adapt the error metrics to a hierarchical setting by using `multilevel` argument to obtain scores for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_smape = MeanAbsolutePercentageError(symmetric=True, multilevel=\"raw_values\")\n",
    "errors_local = hier_smape(y_test, y_pred)\n",
    "errors_local"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the same regressor, we do global forecasting by setting the `pooling` argument to `global`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=12, pooling=\"global\")\n",
    "\n",
    "y_pred = forecaster.fit_predict(y_train, fh=[1, 2, 3, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the scores for the `local` and `global` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_global = hier_smape(y_test, y_pred)\n",
    "\n",
    "print(f\"Average sMAPE with local pooling: {errors_local.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with global pooling: {errors_global.mean().iloc[0]:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick recap of what we have covered in this notebook:\n",
    "\n",
    "- Univariate forecasting (stats and ML)\n",
    "- Univariate with exogenous data\n",
    "- Multivariate forecasting\n",
    "- Probabilistic forecasting\n",
    "- Hierarchical forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits: notebook 3 - forecasting\n",
    "\n",
    "notebook creation: marrov, fkiraly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata_sktime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
